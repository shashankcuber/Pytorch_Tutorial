{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJN0tpuUnTjEHuBZgnok8y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Making the whole model pipeline in pytorch\n","\n","1. Design the model (input, output_size, fwd pass)\n","2. construct loss and optimizer\n","3. training loop\n","\n","- forward pass: compute prediction\n","- backward pass : gradients\n","- update weights "],"metadata":{"id":"IvZUFWrhwPHo"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"sMjVdHgqwYgK","executionInfo":{"status":"ok","timestamp":1668135189731,"user_tz":420,"elapsed":220,"user":{"displayName":"Shashank Pathak","userId":"01797536954556681088"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# prepare data\n","bc = datasets.load_breast_cancer()\n","X, y = bc.data, bc.target\n","\n","n_samples, n_features = X.shape\n","\n","print(n_samples, n_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0klShqhwrc7","executionInfo":{"status":"ok","timestamp":1668135190023,"user_tz":420,"elapsed":5,"user":{"displayName":"Shashank Pathak","userId":"01797536954556681088"}},"outputId":"c744b659-de89-4ba7-f212-6625acea9ea6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["569 30\n"]}]},{"cell_type":"code","source":["X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","\n","#scale the features\n","sc = StandardScaler()\n","\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.fit_transform(X_test)\n","\n","#convert to torch tensors\n","X_train = torch.from_numpy(X_train.astype(np.float32))\n","X_test  = torch.from_numpy(X_test.astype(np.float32))\n","y_train = torch.from_numpy(y_train.astype(np.float32))\n","y_test = torch.from_numpy(y_test.astype(np.float32))\n","\n","\n","# making y_train as column vector as tensors will be a 2d list sort of\n","y_train = y_train.view(y_train.shape[0],1)\n","y_test = y_test.view(y_test.shape[0],1)\n"],"metadata":{"id":"EfE_a7D2w0Kj","executionInfo":{"status":"ok","timestamp":1668135190023,"user_tz":420,"elapsed":3,"user":{"displayName":"Shashank Pathak","userId":"01797536954556681088"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class LogisticRegression(nn.Module):\n","  def __init__(self, n_input_features):\n","    super(LogisticRegression,self).__init__()\n","    self.linear = nn.Linear(n_input_features, 1)\n","  \n","\n","  def forward(self, x):\n","    y_predicted = torch.sigmoid(self.linear(x))\n","    return y_predicted\n","\n","#layer will be having size 30*1\n","model = LogisticRegression(n_features)\n","\n","#cross entropy loss\n","loss_criterion = nn.BCELoss()\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","\n","\n","#training loop\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","  #fwd pass\n","  y_predicted = model(X_train)\n","\n","  loss = loss_criterion(y_predicted, y_train)\n","\n","  #bwd propogation\n","  loss.backward()\n","\n","  optimizer.step()\n","\n","  optimizer.zero_grad()\n","\n","  if (epoch+1)%10 ==0:\n","    print(f'epoch: {epoch+1} , loss={loss.item():.4f}')\n","\n","\n","#evaluation now our old computational graph should not be there\n","with torch.no_grad():\n","  y_predicted = model(X_test)\n","  y_predicted_cls = y_predicted.round()\n","  acc = y_predicted_cls.eq(y_test).sum()/ float(y_test.shape[0])\n","  print(f'accuracy = {acc:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"InF0thwtyYhI","executionInfo":{"status":"ok","timestamp":1668135190280,"user_tz":420,"elapsed":259,"user":{"displayName":"Shashank Pathak","userId":"01797536954556681088"}},"outputId":"00b7d94f-bb8c-4c40-9166-29c05f29e5f8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 10 , loss=0.5051\n","epoch: 20 , loss=0.4379\n","epoch: 30 , loss=0.3916\n","epoch: 40 , loss=0.3574\n","epoch: 50 , loss=0.3309\n","epoch: 60 , loss=0.3097\n","epoch: 70 , loss=0.2923\n","epoch: 80 , loss=0.2776\n","epoch: 90 , loss=0.2651\n","epoch: 100 , loss=0.2542\n","accuracy = 0.9474\n"]}]}]}